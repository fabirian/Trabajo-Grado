{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1gMvHeyV_8tRJzFdZeXAWtDqYkicu3GLz",
      "authorship_tag": "ABX9TyNAaZnBxDLMZYllibZ+KWPD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabirian/Trabajo-Grado/blob/main/Model_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CARGA E IMPORTACION DE LAS LIBRERIAS NECESARIAS"
      ],
      "metadata": {
        "id": "nNWrzX58TTzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from fpdf import FPDF\n",
        "from gensim.models import Word2Vec\n",
        "from keras import Model\n",
        "from keras.layers import (Concatenate, Conv2D, Dense, Dropout, Embedding, Input, LSTM)\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
        "from PIL import Image\n",
        "from rouge import Rouge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications import DenseNet121, InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tqdm import tqdm\n",
        "from keras.initializers import GlorotUniform, HeNormal\n",
        "from keras.layers import BatchNormalization\n",
        "from keras import regularizers\n",
        "from keras.layers import GRU\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "naQDeq_PFA2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e043768-9c10-4b60-82db-65908d5e6e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROCESAMIENTO DE IMAGENES"
      ],
      "metadata": {
        "id": "ek4LblByTiCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CARGA DEL MODELO USADO PARA EXTRACCION DE CARACTERISTICAS"
      ],
      "metadata": {
        "id": "ztjvzJt2Tcmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el modelo preentrenado InceptionV3\n",
        "\n",
        "model = InceptionV3(include_top=False, weights='imagenet')\n",
        "\n",
        "# Definiendo la capa de entrada y la capa de salida\n",
        "input_layer = model.input\n",
        "output_layer = model.layers[-2].output\n",
        "\n",
        "# Creando el modelo\n",
        "image_model = tf.keras.Model(input_layer, output_layer)"
      ],
      "metadata": {
        "id": "n_KTJA6yGQAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2f0308-cf63-47a8-851d-f922d1c45995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCION DE PROCESAMIENTO DE IMAGENES"
      ],
      "metadata": {
        "id": "ooCxIO_sTnM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image_path, path, target_size=(350, 350)):\n",
        "    '''\n",
        "    Entrada -- image_path: ruta de la imagen, path: directorio base de la imagen\n",
        "    Salida -- tensor de imagen int32\n",
        "    '''\n",
        "\n",
        "    # Unir el directorio base con el nombre de la imagen\n",
        "    full_image_path = os.path.join(path, image_path)\n",
        "\n",
        "    img = image.load_img(full_image_path, target_size=target_size)\n",
        "\n",
        "    # Convertir la imagen a un arreglo y preprocesar.\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)  # Utiliza la función de preprocesamiento de InceptionV3.\n",
        "\n",
        "    # Añadir una dimensión para formar un lote de tamaño 1.\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Cargar el modelo y predecir.\n",
        "    features = model.predict(img_batch)\n",
        "\n",
        "    features = tf.cast(features, tf.float32)\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "Z8fOmULvGnS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the tensor using train and validation data and store it in list\n",
        "\n",
        "path = '/home/gico/Neumonia/Img_Completo/'\n",
        "\n",
        "# Cargos los distintos tipos de dataset\n",
        "\n",
        "# Data Normal\n",
        "#train = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConLimpieza/train_data_normalizada_sindup.csv')\n",
        "#validation = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConLimpieza/validation_data_normalizada_sindup.csv')\n",
        "#Dataser Reducido\n",
        "#train = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConLimpieza/train_datos_sololimpieza.csv')\n",
        "#validation = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConLimpieza/validationdatos_sololimpieza.csv')\n",
        "\n",
        "# Data Normalizado solo sin hallazgos\n",
        "#train = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosNormalizadoSóloSinHallazgos/train_data_normalizada_sindup.csv')\n",
        "#validation = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosNormalizadoSóloSinHallazgos/validation_data_normalizada_sindup.csv')\n",
        "#Dataser Reducido\n",
        "#train = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosNormalizadoSóloSinHallazgos/train_datos_solo_sinhallazgo.csv')\n",
        "#validation = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosNormalizadoSóloSinHallazgos/validationdatos_solo_sinhallazgo.csv')\n",
        "\n",
        "# Data Normalizado reportes separados\n",
        "train = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConClusterNormalizadosReportesPorSeparado/train_data_normalizada_sindup.csv')\n",
        "validation = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConClusterNormalizadosReportesPorSeparado/validation_data_normalizada_sindup.csv')\n",
        "\n",
        "# Data Normalizado reportes compuestos\n",
        "#train = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConClusterNormalizadosReportesCompuestos/train_data_normalizada_sindup.csv')\n",
        "#validation = pd.read_csv('/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConClusterNormalizadosReportesCompuestos/validation_data_normalizada_sindup.csv')\n",
        "\n",
        "diccionario = pd.read_csv('/home/gico/Neumonia/Archivos_csv/filtered_terms_dictionary.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "42b_-IFLGph5",
        "outputId": "058cd993-15df-4aa4-f246-ee8a3b1d0bd0",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-720c3d9ac851>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Data Normalizado reportes separados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConClusterNormalizadosReportesPorSeparado/train_data_normalizada_sindup.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/gico/Neumonia/Archivos_csv/DatosModelo/DatosConClusterNormalizadosReportesPorSeparado/validation_data_normalizada_sindup.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesar Datos\n",
        "train = train.iloc[:, 0:]\n",
        "validation = validation.iloc[:, 0:]\n",
        "diccionario = diccionario.iloc[:, 0:]\n",
        "\n",
        "\n",
        "# Convertir los reportes a minúsculas\n",
        "train['Report'] = train['Report'].str.lower()\n",
        "validation['Report'] = validation['Report'].str.lower()\n",
        "diccionario['term'] = diccionario['term'].str.lower()\n",
        "\n",
        "# añadir los tokenizer <start> y <end> a los dataset\n",
        "\n",
        "train.Report      = '<start> ' + train.Report + ' <end>'\n",
        "validation.Report = '<start> ' + validation.Report + ' <end>'\n",
        "diccionario = '<start> ' + diccionario + ' <end>'\n",
        "\n",
        "# Datos de train\n",
        "image_train = [ ]\n",
        "for col in tqdm(train.values):\n",
        "    tensor = preprocess(col[1], path)\n",
        "    image_train.append(tensor)\n",
        "\n",
        "# Datos de validation\n",
        "image_validation = [ ]\n",
        "for col in tqdm(validation.values):\n",
        "    tensor = preprocess(col[1], path)\n",
        "    image_validation.append(tensor)\n",
        "\n",
        "# Guardar los tensores en formato numpy\n",
        "np.save(\"/home/gico/Neumonia/Tensores/train_image_features_3\", image_train)\n",
        "np.save(\"/home/gico/Neumonia/Tensores/validation_image_features_3\",  image_validation)\n",
        "\n",
        "image_train = np.load('/home/gico/Neumonia/Tensores/train_image_features_3.npy')\n",
        "image_validation = np.load('/home/gico/Neumonia/Tensores/validation_image_features_3.npy')"
      ],
      "metadata": {
        "id": "Ao4reQgkiTVc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROCESAMIENTO DE TEXTO"
      ],
      "metadata": {
        "id": "8O1f42F_TvGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCIONES PARA PROCESAMIENTO DE TEXTO"
      ],
      "metadata": {
        "id": "4KxBvA8ETx_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_text_data(df, text_column):\n",
        "    # Asegurar que las columnas de texto son de tipo string\n",
        "    df[text_column] = df[text_column].astype(str)\n",
        "    return df\n",
        "\n",
        "def create_tokenizer(train_texts):\n",
        "    # Definir el tokenizador con los filtros adecuados, excluyendo apostrofes para capturar contracciones como \"don't\"\n",
        "    tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^`{|}~\\t\\n')\n",
        "    tokenizer.fit_on_texts(train_texts)\n",
        "    return tokenizer\n",
        "\n",
        "def tokenize_and_pad(texts, tokenizer, max_len):\n",
        "    # Convertir los textos a secuencias y rellenar\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded = pad_sequences(sequences, maxlen=int(max_len), padding='post', truncating='post')\n",
        "    return padded\n",
        "\n",
        "def get_max_length(train_sequences, percentile=95):\n",
        "    # Ajuste dinámico del tamaño de secuencia basado en un percentil\n",
        "    max = np.percentile([len(x) for x in train_sequences], percentile)\n",
        "    return int(np.ceil(max)) + 1\n",
        "\n",
        "def train_word2vec(texts, vector_size=300, window=5, min_count=1, workers=4):\n",
        "    # Preparar el corpus de texto y entrenar el modelo Word2Vec\n",
        "    list_sents = [nltk.word_tokenize(sent) for text in texts for sent in nltk.sent_tokenize(text)]\n",
        "    w2v_model = Word2Vec(sentences=list_sents, vector_size=vector_size, window=window, min_count=min_count, workers=workers)\n",
        "    return w2v_model\n",
        "\n",
        "def create_embedding_matrix(word_index, w2v_model, vector_size=300):\n",
        "    # Crear una matriz de pesos para las palabras en documentos de entrenamiento\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, vector_size))\n",
        "    for word, i in tqdm(word_index.items()):\n",
        "        if word in w2v_model.wv:\n",
        "            embedding_vector = w2v_model.wv[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "yu62_7pKYLBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar los datos de texto\n",
        "train = prepare_text_data(train, 'Report')\n",
        "validation = prepare_text_data(validation, 'Report')\n",
        "diccionario = prepare_text_data(diccionario, 'term')\n",
        "\n",
        "# Tokenización y padding\n",
        "#combined_texts = pd.concat([train['Report'], diccionario['term']])\n",
        "tokenizer = create_tokenizer(train['Report'])\n",
        "max_len = get_max_length(tokenizer.texts_to_sequences(train['Report']))\n",
        "pad_train = tokenize_and_pad(train['Report'], tokenizer, max_len)\n",
        "pad_val = tokenize_and_pad(validation['Report'], tokenizer, max_len)\n",
        "\n",
        "# Crear diccionarios para mapear índices a palabras y viceversa\n",
        "word_idx = tokenizer.word_index\n",
        "idx_word = {v: k for k, v in word_idx.items()}\n",
        "\n",
        "# Calcular el tamaño del vocabulario (agregando uno por el token de padding 0)\n",
        "vocab_size = len(word_idx) + 1\n",
        "\n",
        "# Entrenamiento del modelo FastText\n",
        "#texts = combined_texts.tolist()\n",
        "w2v_model = train_word2vec(train['Report'])\n",
        "\n",
        "# Creación de la matriz de embedding\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, w2v_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1AfadTV2E2L",
        "outputId": "250a3ba5-e5e6-4ae0-c341-da49faab528e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 121/121 [00:00<00:00, 59129.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREACION DE DATASET NECESARIOS"
      ],
      "metadata": {
        "id": "fSfiYT-nT4EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de hiperparámetros y constantes\n",
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "PREFETCH_BUFFER_SIZE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def prepare_datasets(image_train, pad_train, image_validation, pad_va):\n",
        "    \"\"\"\n",
        "    Prepara datasets de entrenamiento y validación con imágenes, texto preprocesado y localizaciones.\n",
        "\n",
        "    Args:\n",
        "        image_train (np.array): Imágenes de entrenamiento.\n",
        "        pad_train (np.array): Texto de entrenamiento preprocesado y tokenizado.\n",
        "        loc_train (np.array): Localizaciones de entrenamiento codificadas.\n",
        "        image_validation (np.array): Imágenes de validación.\n",
        "        pad_val (np.array): Texto de validación preprocesado y tokenizado.\n",
        "        loc_val (np.array): Localizaciones de validación codificadas.\n",
        "\n",
        "    Returns:\n",
        "        train_dataset (tf.data.Dataset): Dataset de entrenamiento.\n",
        "        val_dataset (tf.data.Dataset): Dataset de validación.\n",
        "    \"\"\"\n",
        "    # Dataset de entrenamiento\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((image_train, pad_train))\n",
        "    train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER_SIZE)\n",
        "\n",
        "    # Dataset de validación\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((image_validation, pad_val))\n",
        "    val_dataset = val_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER_SIZE)\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "# Ejemplo de uso de la función modificada\n",
        "train_dataset, val_dataset = prepare_datasets(image_train, pad_train, image_validation, pad_val)\n"
      ],
      "metadata": {
        "id": "Gs_aUwSAYSGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELOS ENCODER - DECODER"
      ],
      "metadata": {
        "id": "os2Im_-uT8IX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELO ENCODER Y FUNCION DE ATECION PARA ENCODER"
      ],
      "metadata": {
        "id": "eTUTeWXHT_Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.query_dense = Dense(units=self.embedding_dim)  # Genera los queries\n",
        "        self.key_dense = Dense(units=self.embedding_dim)    # Genera las keys\n",
        "        self.value_dense = Dense(units=self.embedding_dim)  # Genera los values\n",
        "\n",
        "    def call(self, x):\n",
        "        query = self.query_dense(x)\n",
        "        key = self.key_dense(x)\n",
        "        value = self.value_dense(x)\n",
        "        scores = tf.matmul(query, key, transpose_b=True) / tf.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
        "        weights = tf.nn.softmax(scores, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, dropout_rate=0.3, seed=None, debug=False):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.debug = debug\n",
        "        self.seed = seed if seed is not None else 40\n",
        "\n",
        "        self.dense1 = Dense(units=self.embedding_dim, activation='relu',\n",
        "                            kernel_initializer=GlorotUniform(seed=self.seed),\n",
        "                            name='encoder_dense_layer_1')\n",
        "        self.attention = SelfAttention(embedding_dim=self.embedding_dim)\n",
        "        self.dropout1 = Dropout(dropout_rate, name='encoder_dropout_1')\n",
        "        self.dense_final = Dense(units=self.embedding_dim, activation='relu',\n",
        "                                 kernel_initializer=GlorotUniform(seed=self.seed),\n",
        "                                 name='encoder_dense_layer_final')\n",
        "        self.reshape = Reshape((81,2048))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        print(inputs.shape)\n",
        "        x = self.reshape(inputs)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.attention(x)\n",
        "        x = self.dense_final(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "EhjkDi2gG9av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELO DECODER Y FUNCION DE ATENCION PARA DECODER"
      ],
      "metadata": {
        "id": "aaNSzIGoUF7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "D83Bx1IDG_1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definicion clase Decoder\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, lstm_units, vocab_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True,\n",
        "                                                   weights=[embedding_matrix],\n",
        "                                                   name='Decoder_embedding')\n",
        "        self.bidir_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(\n",
        "                                                            lstm_units,\n",
        "                                                            return_sequences=True,\n",
        "                                                            return_state=True,\n",
        "                                                            dropout=0.3\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size,\n",
        "                                           activation=None,\n",
        "                                           kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45),\n",
        "                                           name='Decoder_dense'\n",
        "                                        )\n",
        "        self.attention = BahdanauAttention(lstm_units)\n",
        "        self.concat = tf.keras.layers.Concatenate()\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, x, features, forward_h, forward_c, backward_h, backward_c):\n",
        "        x = self.embedding(x)\n",
        "        state = self.concat([forward_h, backward_h])\n",
        "        context_vector, attention_weights = self.attention(features, state)\n",
        "        result = tf.concat([tf.expand_dims(context_vector, axis=1), x], axis=-1)\n",
        "\n",
        "        # Note: initial_state for LSTM includes both hidden state and cell state\n",
        "        lstm_out, forward_h, forward_c, backward_h, backward_c = self.bidir_lstm(result, initial_state=[forward_h, forward_c, backward_h, backward_c])\n",
        "        lstm_out = self.batch_norm(lstm_out)\n",
        "        outputs = tf.reshape(lstm_out, (-1, lstm_out.shape[-1]))\n",
        "        dense_out = self.dense(outputs)\n",
        "        return dense_out, forward_h, forward_c, backward_h, backward_c, attention_weights"
      ],
      "metadata": {
        "id": "oWBE4267HBm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "z1fGfBirUNg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCIONES DE PERDIDA, EXACTITUD Y OPTIMIZADOR"
      ],
      "metadata": {
        "id": "JJBd0CN-UP8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar la tasa de aprendizaje inicial y el decaimiento\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n",
        "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "acc_obj = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "def loss_func(real, pred):\n",
        "    \"\"\"Loss calculation\"\"\"\n",
        "    loss_f = loss_obj(real, pred)\n",
        "    return tf.reduce_mean(loss_f)\n",
        "\n",
        "def acc_func(real, pred):\n",
        "    \"\"\"Accuracy calculation\"\"\"\n",
        "    acc_f = acc_obj(real, pred)\n",
        "    return tf.reduce_mean(acc_f)"
      ],
      "metadata": {
        "id": "LbHY7z2qHD3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "encoder = Encoder(embedding_dim = embedding_dim)\n",
        "\n",
        "lstm_units = 1000\n",
        "decoder = Decoder(embedding_dim = embedding_dim, lstm_units = lstm_units , vocab_size = vocab_size)"
      ],
      "metadata": {
        "id": "s0U_TBiJHGwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCIONES DE TRAIN Y VAL"
      ],
      "metadata": {
        "id": "YXrI8uLTUcHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(autograph=True)\n",
        "def train_step(tensor, target):\n",
        "    loss = 0\n",
        "    train_acc = 0\n",
        "\n",
        "    # Inicialización de los estados ocultos y de celda para las LSTM bidireccionales\n",
        "    forward_h = tf.zeros((target.shape[0], lstm_units))\n",
        "    forward_c = tf.zeros((target.shape[0], lstm_units))\n",
        "    backward_h = tf.zeros((target.shape[0], lstm_units))\n",
        "    backward_c = tf.zeros((target.shape[0], lstm_units))\n",
        "\n",
        "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        features = encoder(tensor)\n",
        "        for i in range(1, target.shape[1]):\n",
        "            # Llamada al decoder con los estados ocultos y de celda\n",
        "            predictions, forward_h, forward_c, backward_h, backward_c, _ = decoder(dec_input, features, forward_h, forward_c, backward_h, backward_c)\n",
        "            loss += loss_func(target[:, i], predictions)\n",
        "            train_acc += acc_func(target[:, i], predictions)\n",
        "            dec_input = tf.expand_dims(target[:, i], 1)\n",
        "\n",
        "    total_loss = loss / int(target.shape[1])\n",
        "    total_acc = train_acc / int(target.shape[1])\n",
        "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "    return loss, total_loss, total_acc\n",
        "\n",
        "\n",
        "@tf.function(autograph=True)\n",
        "def val_step(tensor, target):\n",
        "    loss_val = 0\n",
        "    test_acc = 0\n",
        "    forward_h = tf.zeros((target.shape[0], lstm_units))\n",
        "    forward_c = tf.zeros((target.shape[0], lstm_units))\n",
        "    backward_h = tf.zeros((target.shape[0], lstm_units))\n",
        "    backward_c = tf.zeros((target.shape[0], lstm_units))\n",
        "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
        "    features = encoder(tensor)\n",
        "\n",
        "    for i in range(1, target.shape[1]):\n",
        "        predictions_val, forward_h, forward_c, backward_h, backward_c, _ = decoder(dec_input, features, forward_h, forward_c, backward_h, backward_c)\n",
        "        loss_val += loss_func(target[:, i], predictions_val)\n",
        "        test_acc += acc_func(target[:, i], predictions_val)\n",
        "        dec_input = tf.expand_dims(target[:, i], 1)\n",
        "\n",
        "    total_loss_val = loss_val / int(target.shape[1])\n",
        "    return loss_val, total_loss_val, test_acc"
      ],
      "metadata": {
        "id": "ewc1Y4ixHKh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENTRENAMIENTO DEL MODELO"
      ],
      "metadata": {
        "id": "4hWKOaaEUgDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENTRENAMIENTO DATASET ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "lwBCpLFoUkij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "EPOCHS = 30\n",
        "\n",
        "loss_plot_train = []\n",
        "loss_plot_val = []\n",
        "acc_plot_train = []\n",
        "acc_plot_val = []\n",
        "num_steps = 64\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss_train = 0\n",
        "    total_loss_val = 0\n",
        "    total_acc_train = 0\n",
        "    total_acc_val = 0\n",
        "    acc_obj.reset_states()\n",
        "\n",
        "    # Iterando sobre el dataset de entrenamiento\n",
        "    for (batch, (img_tensor, target)) in enumerate(train_dataset):\n",
        "        batch_loss, t_loss, t_acc = train_step(img_tensor, target)\n",
        "        total_loss_train += t_loss\n",
        "        total_acc_train += t_acc\n",
        "\n",
        "    # Promedio de la precisión de entrenamiento\n",
        "    avg_acc_train = total_acc_train / num_steps\n",
        "    acc_plot_train.append(avg_acc_train)\n",
        "    loss_plot_train.append(total_loss_train / num_steps)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch + 1} Train Loss: {total_loss_train / num_steps:.6f} Train Accuracy: {avg_acc_train:.6f}')\n",
        "    print(f'Time taken for epoch: {time.time() - start} sec\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUZiAZHfHXd_",
        "outputId": "b54d259c-78b0-47b3-fc22-4cb68f1f0fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (16, 1, 2048)\n",
            "After dense1 shape: (16, 1, 300)\n",
            "After attention shape: (16, 1, 300)\n",
            "After dropout shape: (16, 1, 300)\n",
            "Final output shape: (16, 1, 300)\n",
            "Input shape: (16, 1, 2048)\n",
            "After dense1 shape: (16, 1, 300)\n",
            "After attention shape: (16, 1, 300)\n",
            "After dropout shape: (16, 1, 300)\n",
            "Final output shape: (16, 1, 300)\n",
            "Epoch 1 Train Loss: 0.072767 Train Accuracy: 0.004767\n",
            "Time taken for epoch: 179.29351449012756 sec\n",
            "\n",
            "Epoch 2 Train Loss: 0.076128 Train Accuracy: 0.005405\n",
            "Time taken for epoch: 0.2369518280029297 sec\n",
            "\n",
            "Epoch 3 Train Loss: 0.072641 Train Accuracy: 0.001089\n",
            "Time taken for epoch: 0.21404600143432617 sec\n",
            "\n",
            "Epoch 4 Train Loss: 0.070576 Train Accuracy: 0.005586\n",
            "Time taken for epoch: 0.20418524742126465 sec\n",
            "\n",
            "Epoch 5 Train Loss: 0.069112 Train Accuracy: 0.005520\n",
            "Time taken for epoch: 0.2056901454925537 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENTRENAMIENTO DATASET VALIDACION"
      ],
      "metadata": {
        "id": "jCk5mPW5Uobp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss_train = 0\n",
        "    total_loss_val = 0\n",
        "    total_acc_train = 0\n",
        "    total_acc_val = 0\n",
        "    acc_obj.reset_states()\n",
        "\n",
        "    # Iterando sobre el dataset de validación\n",
        "    for (batch, (img_tensor, target)) in enumerate(val_dataset):\n",
        "        batch_loss, t_loss, t_acc = val_step(img_tensor, target)\n",
        "        total_loss_val += t_loss\n",
        "        total_acc_val += t_acc\n",
        "\n",
        "    # Promedio de la precisión de validación\n",
        "    avg_acc_val = total_acc_val / num_steps\n",
        "    acc_plot_val.append(avg_acc_val)\n",
        "    loss_plot_val.append(total_loss_val / num_steps)\n",
        "\n",
        "    print(f'Epoch {epoch + 1} ')\n",
        "    print(f'Validation Loss: {total_loss_val / num_steps:.6f} Validation Accuracy: {avg_acc_val:.6f}')\n",
        "    print(f'Time taken for epoch: {time.time() - start} sec\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnVACq-PiZJj",
        "outputId": "d787eb3d-1de3-40d1-9c8d-286980cd0236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (4, 1, 2048)\n",
            "After dense1 shape: (4, 1, 300)\n",
            "After attention shape: (4, 1, 300)\n",
            "After dropout shape: (4, 1, 300)\n",
            "Final output shape: (4, 1, 300)\n",
            "Epoch 1 \n",
            "Validation Loss: 0.071580 Validation Accuracy: 0.253004\n",
            "Time taken for epoch: 58.5090389251709 sec\n",
            "\n",
            "Epoch 2 \n",
            "Validation Loss: 0.071580 Validation Accuracy: 0.253004\n",
            "Time taken for epoch: 0.07205653190612793 sec\n",
            "\n",
            "Epoch 3 \n",
            "Validation Loss: 0.071580 Validation Accuracy: 0.253004\n",
            "Time taken for epoch: 0.06828713417053223 sec\n",
            "\n",
            "Epoch 4 \n",
            "Validation Loss: 0.071580 Validation Accuracy: 0.253004\n",
            "Time taken for epoch: 0.07213568687438965 sec\n",
            "\n",
            "Epoch 5 \n",
            "Validation Loss: 0.071580 Validation Accuracy: 0.253004\n",
            "Time taken for epoch: 0.09007883071899414 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INFORMACION DE ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "ts4d9q8gUsOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRAFICAS DE PERDIDA Y EXACTITUD"
      ],
      "metadata": {
        "id": "CXzVMysUUxVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfica combinada de pérdida de entrenamiento y validación\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_plot_train, label='Training Loss')\n",
        "plt.plot(acc_plot_train, label='Training Accuracy')\n",
        "plt.title('Loss y Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('/home/gico/Neumonia/Datos/Datos_entrenamiento/combined.png')\n",
        "plt.close()\n",
        "\n",
        "# Gráfica combinada de precisión de entrenamiento y validación\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_plot_val, label='Validation Loss')\n",
        "plt.plot(acc_plot_val, label='Validation Accuracy')\n",
        "plt.title('Training & Validation Accuracy per Epoch')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('/home/gico/Neumonia/Datos/Datos_entrenamiento/combined_val.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "N-tvM1MhHdlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREACION PDF DE LAS GRAFICAS"
      ],
      "metadata": {
        "id": "6Q6rGCNsU3Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase PDF para incluir gráficos en el documento\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, 'Training Report', 0, 1, 'C')\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, title, 0, 1, 'L')\n",
        "\n",
        "    def add_plot(self, img_file):\n",
        "        self.image(img_file, x=10, w=180)  # Ajusta según necesidad\n",
        "\n",
        "# Creación del documento PDF\n",
        "pdf = PDF()\n",
        "pdf.add_page()\n",
        "pdf.set_font('Arial', 'B', 16)\n",
        "pdf.cell(0, 10, 'Training and Validation Curves', 0, 1, 'C')\n",
        "\n",
        "# Agregar las gráficas de pérdida combinada\n",
        "pdf.chapter_title('Training')\n",
        "pdf.add_plot('/home/gico/Neumonia/Datos/Datos_entrenamiento/combined.png')\n",
        "\n",
        "# Agregar las gráficas de precisión combinada\n",
        "pdf.chapter_title(' Validation')\n",
        "pdf.add_plot('/home/gico/Neumonia/Datos/Datos_entrenamiento/combined_val.png')\n",
        "\n",
        "# Guardar el PDF\n",
        "pdf.output('/home/gico/Neumonia/Datos/Datos_entrenamiento/Training_Validation_Report.pdf')"
      ],
      "metadata": {
        "id": "xyvXUwtnHoO6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf38a030-8851-4d7d-cabf-23064b01a718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUACION DEL MODELO"
      ],
      "metadata": {
        "id": "u6unzwxkU8-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCION DE GENERACION"
      ],
      "metadata": {
        "id": "MEOtFR78U_EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(image_path, path, top_k=10):\n",
        "    \"\"\"Generates captions for an image using Top-K sampling.\"\"\"\n",
        "    attention_shape =81\n",
        "    max_len_output = max_len\n",
        "\n",
        "    img_tensor_val = preprocess(image_path, path)\n",
        "    features = encoder(img_tensor_val)\n",
        "    forward_h = tf.zeros((1, lstm_units))\n",
        "    forward_c = tf.zeros((1, lstm_units))\n",
        "    backward_h = tf.zeros((1, lstm_units))\n",
        "    backward_c = tf.zeros((1, lstm_units))\n",
        "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    result = []\n",
        "    text = \"\"\n",
        "    attention_plot = np.zeros((max_len_output, attention_shape))\n",
        "\n",
        "    for i in range(max_len_output):\n",
        "        predictions, forward_h, forward_c, backward_h, backward_c, attention_weights = decoder(dec_input, features, forward_h, forward_c, backward_h, backward_c)\n",
        "        attention_plot[i] = tf.reshape(attention_weights, (-1)).numpy()\n",
        "\n",
        "        # Aplicar Top-K Sampling\n",
        "        top_k_values, top_k_indices = tf.nn.top_k(predictions, k=top_k, sorted=True)\n",
        "        top_k_probs = tf.nn.softmax(top_k_values).numpy().flatten()\n",
        "        chosen_index = np.random.choice(top_k_indices.numpy().flatten(), p=top_k_probs)\n",
        "\n",
        "        predicted_word = tokenizer.index_word.get(chosen_index, '<unk>')\n",
        "        if predicted_word == '<end>':\n",
        "            break\n",
        "        result.append(predicted_word)\n",
        "        text += ' ' + predicted_word\n",
        "        dec_input = tf.expand_dims([chosen_index], 0)\n",
        "\n",
        "    attention_plot = attention_plot[:len(result), :]\n",
        "\n",
        "    if not text.strip():\n",
        "        return [], \"No se generó texto\", attention_plot\n",
        "\n",
        "    return result, text, attention_plot"
      ],
      "metadata": {
        "id": "u2bdrkc6Hsty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCION DE EVALUACION"
      ],
      "metadata": {
        "id": "nL9920bRVA4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_img_cap(index, path):\n",
        "    # Seleccionar un punto de datos de validación\n",
        "    img_data = validation.iloc[index]\n",
        "    img_path = img_data['ImageID']\n",
        "    actual_report = img_data['Report']\n",
        "\n",
        "    actual_report = actual_report.replace('<start>', '').replace('<end>', '').strip()\n",
        "\n",
        "    # Concatenar la ruta completa del archivo\n",
        "    full_path = os.path.join(path, img_path)\n",
        "    # Generar el reporte médico predicho\n",
        "    result, text,  attention = generate(img_path, path)\n",
        "\n",
        "    text = text.replace('<start>', '').replace('<end>', '').strip()\n",
        "\n",
        "    # Cargar la imagen\n",
        "    img = Image.open(full_path)\n",
        "    result = result[:-1]\n",
        "\n",
        "    # Calcular BLEU y ROUGE scores\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    bleu_scores = {\n",
        "        'BLEU-1': sentence_bleu([actual_report], text, weights=(1, 0, 0, 0), smoothing_function=smoothie),\n",
        "        'BLEU-2': sentence_bleu([actual_report], text, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie),\n",
        "        'BLEU-3': sentence_bleu([actual_report], text, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoothie),\n",
        "        'BLEU-4': sentence_bleu([actual_report], text, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
        "    }\n",
        "    rouge = Rouge()\n",
        "    rouge_scores = rouge.get_scores(text, actual_report)\n",
        "\n",
        "    return full_path, attention, actual_report, text, result, bleu_scores, rouge_scores"
      ],
      "metadata": {
        "id": "avHSMifOHvWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUCION DE IMAGENES AL AZAR"
      ],
      "metadata": {
        "id": "kbzyqSLeVEBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_indices = random.sample(range(len(validation)), 10)\n",
        "results = [test_img_cap(index, path) for index in random_indices]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMhVoItXtfNm",
        "outputId": "91533e31-af0f-445e-f150-3d4a3c1c01f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 446ms/step\n",
            "Input shape: (1, 2048)\n",
            "After dense1 shape: (1, 300)\n",
            "After attention shape: (1, 300)\n",
            "After dropout shape: (1, 300)\n",
            "Final output shape: (1, 300)\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Input shape: (1, 2048)\n",
            "After dense1 shape: (1, 300)\n",
            "After attention shape: (1, 300)\n",
            "After dropout shape: (1, 300)\n",
            "Final output shape: (1, 300)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Input shape: (1, 2048)\n",
            "After dense1 shape: (1, 300)\n",
            "After attention shape: (1, 300)\n",
            "After dropout shape: (1, 300)\n",
            "Final output shape: (1, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image_with_report(index, image_path, actual_report, text, predicted_report, bleu_scores, rouge_scores, output_path):\n",
        "    # Procesar reportes para remover los tokens\n",
        "    actual_report_clean = actual_report.replace('<start>', '').replace('<end>', '').strip()\n",
        "    predicted_report_clean = text.replace('<start>', '').replace('<end>', '').strip()\n",
        "\n",
        "    img = Image.open(image_path)  # Abrir la imagen directamente sin manipulación de color\n",
        "    img_array = np.array(img)     # Convertir la imagen a un arreglo de numpy\n",
        "\n",
        "    # Crea una figura y dos subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Muestra la imagen en el primer subplot\n",
        "    ax1.imshow(img_array, cmap = 'bone')\n",
        "    ax1.axis('off')  # Desactivar ejes\n",
        "\n",
        "    # Prepara el texto del reporte y métricas\n",
        "    report_and_metrics_text = (\n",
        "        f\"Image Name: {image_path}\\n\\n\"\n",
        "        f\"Actual report: {actual_report_clean}\\n\\n\"\n",
        "        f\"Predicted report: {predicted_report_clean}\\n\\n\"\n",
        "        f\"BLEU-1: {bleu_scores['BLEU-1']:.4f}\\n\"\n",
        "        f\"BLEU-2: {bleu_scores['BLEU-2']:.4f}\\n\"\n",
        "        f\"BLEU-3: {bleu_scores['BLEU-3']:.4f}\\n\"\n",
        "        f\"BLEU-4: {bleu_scores['BLEU-4']:.4f}\\n\\n\"\n",
        "        f\"ROUGE-1: {rouge_scores[0]['rouge-1']['f']:.4f}\\n\"\n",
        "    )\n",
        "\n",
        "    # Configura el segundo subplot para el texto\n",
        "    ax2.axis('off')\n",
        "    ax2.text(0.01, 0.5, report_and_metrics_text, transform=ax2.transAxes, fontsize=12, verticalalignment='center')\n",
        "\n",
        "    # Guardar la figura en un archivo PNG\n",
        "    plt.savefig(f'{output_path}/image_with_report_{index}.png', bbox_inches='tight')\n",
        "\n",
        "    # Cierra la figura para liberar memoria\n",
        "    plt.close(fig)\n",
        "\n",
        "# Suponiendo que tienes una variable 'results' que ya contiene todos los datos necesarios para generar los informes\n",
        "output_path = \"/home/gico/Neumonia/Datos/Reportes_generados\"\n",
        "for index, (image_path, attention, actual_report, text, predicted_report, bleu_scores, rouge_scores) in enumerate(results):\n",
        "    save_image_with_report(index, image_path, actual_report, text, predicted_report, bleu_scores, rouge_scores, output_path)"
      ],
      "metadata": {
        "id": "FlSndIuRHycn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUACION DEL DATASET DE VALIDACION"
      ],
      "metadata": {
        "id": "3qnxyuWgVG0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_size = len(validation)\n",
        "results = [test_img_cap(index, path) for index in range(validation_size)]\n",
        "\n",
        "# Calcula las métricas medias\n",
        "total_bleu1, total_bleu2, total_bleu3, total_bleu4, total_rouge_l = 0, 0, 0, 0, 0\n",
        "for _, _, _, _, _, bleu_scores, rouge_scores in results:\n",
        "    total_bleu1 += bleu_scores['BLEU-1']\n",
        "    total_bleu2 += bleu_scores['BLEU-2']\n",
        "    total_bleu3 += bleu_scores['BLEU-3']\n",
        "    total_bleu4 += bleu_scores['BLEU-4']\n",
        "    total_rouge_l += rouge_scores[0]['rouge-l']['f']\n",
        "\n",
        "average_bleu1 = total_bleu1 / validation_size\n",
        "average_bleu2 = total_bleu2 / validation_size\n",
        "average_bleu3 = total_bleu3 / validation_size\n",
        "average_bleu4 = total_bleu4 / validation_size\n",
        "average_rouge_l = total_rouge_l / validation_size\n",
        "\n",
        "print(f\"Average BLEU-1: {average_bleu1:.4f}\")\n",
        "print(f\"Average BLEU-2: {average_bleu2:.4f}\")\n",
        "print(f\"Average BLEU-3: {average_bleu3:.4f}\")\n",
        "print(f\"Average BLEU-4: {average_bleu4:.4f}\")\n",
        "print(f\"Average ROUGE-L: {average_rouge_l:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR2eIL2eB2dX",
        "outputId": "60e44968-6e4a-4f59-bec0-8af07eb5b44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 82ms/step\n",
            "Input shape: (1, 2048)\n",
            "After dense1 shape: (1, 300)\n",
            "After attention shape: (1, 300)\n",
            "After dropout shape: (1, 300)\n",
            "Final output shape: (1, 300)\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "Input shape: (1, 2048)\n",
            "After dense1 shape: (1, 300)\n",
            "After attention shape: (1, 300)\n",
            "After dropout shape: (1, 300)\n",
            "Final output shape: (1, 300)\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Input shape: (1, 2048)\n",
            "After dense1 shape: (1, 300)\n",
            "After attention shape: (1, 300)\n",
            "After dropout shape: (1, 300)\n",
            "Final output shape: (1, 300)\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "Input shape: (1, 2048)\n",
            "After dense1 shape: (1, 300)\n",
            "After attention shape: (1, 300)\n",
            "After dropout shape: (1, 300)\n",
            "Final output shape: (1, 300)\n",
            "ROUGE scores structure: [{'rouge-1': {'r': 0.14285714285714285, 'p': 1.0, 'f': 0.24999999781250004}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.14285714285714285, 'p': 1.0, 'f': 0.24999999781250004}}]\n",
            "ROUGE scores structure: [{'rouge-1': {'r': 0.03571428571428571, 'p': 1.0, 'f': 0.06896551657550536}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.03571428571428571, 'p': 1.0, 'f': 0.06896551657550536}}]\n",
            "ROUGE scores structure: [{'rouge-1': {'r': 0.2, 'p': 1.0, 'f': 0.33333333055555564}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.2, 'p': 1.0, 'f': 0.33333333055555564}}]\n",
            "ROUGE scores structure: [{'rouge-1': {'r': 0.2, 'p': 1.0, 'f': 0.33333333055555564}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.2, 'p': 1.0, 'f': 0.33333333055555564}}]\n",
            "Average BLEU-1: 0.0036\n",
            "Average BLEU-2: 0.0036\n",
            "Average BLEU-3: 0.0036\n",
            "Average BLEU-4: 0.0036\n",
            "Average ROUGE-L: 0.2464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yrTC1tbVsCjF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}